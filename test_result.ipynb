{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "lable = {'Abyssinian': 0,\n",
    " 'american_bulldog': 1,\n",
    " 'american_pit_bull_terrier': 2,\n",
    " 'basset_hound': 3,\n",
    " 'beagle': 4,\n",
    " 'Bengal': 5,\n",
    " 'Birman': 6,\n",
    " 'Bombay': 7,\n",
    " 'boxer': 8,\n",
    " 'British_Shorthair': 9,\n",
    " 'chihuahua': 10,\n",
    " 'Egyptian_Mau': 11,\n",
    " 'english_cocker_spaniel': 12,\n",
    " 'english_setter': 13,\n",
    " 'german_shorthaired': 14,\n",
    " 'great_pyrenees': 15,\n",
    " 'havanese': 16,\n",
    " 'japanese_chin': 17,\n",
    " 'keeshond': 18,\n",
    " 'leonberger': 19,\n",
    " 'Maine_Coon': 20,\n",
    " 'miniature_pinscher': 21,\n",
    " 'newfoundland': 22,\n",
    " 'Persian': 23,\n",
    " 'pomeranian': 24,\n",
    " 'pug': 25,\n",
    " 'Ragdoll': 26,\n",
    " 'Russian_Blue': 27,\n",
    " 'saint_bernard': 28,\n",
    " 'samoyed': 29,\n",
    " 'scottish_terrier': 30,\n",
    " 'shiba_inu': 31,\n",
    " 'Siamese': 32,\n",
    " 'Sphynx': 33,\n",
    " 'staffordshire_bull_terrier': 34,\n",
    " 'wheaten_terrier': 35,\n",
    " 'yorkshire_terrier': 36}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"\n",
    "        计算topk的准确率\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        class_to = pred[0].cpu().numpy()\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].contiguous().view(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size))\n",
    "        return res, class_to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torchvision,torch,torch.nn as nn\n",
    "# model = torchvision.models.vit_b_16(progress=True)\n",
    "# # model = torchvision.models.vit_b_16(progress=True)\n",
    "# # model = vit_model.vit_base_patch16_224(num_classes=37)\n",
    "# model.heads = nn.Sequential(nn.Linear(768,out_features=37,bias=True))\n",
    "# stact = torch.load(r'D:\\code\\EML-NET-Saliency-master\\model_best_checkpoint_resnet50.pth.tar',map_location='cpu')\n",
    "# model.load_state_dict(stact['state_dict'])\n",
    "from PIL import Image\n",
    "import torchvision.transforms as tr\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'D:\\data\\animals_catalogy\\data\\1-1.jpg'\n",
    "path_ = r'D:\\data\\animals_catalogy\\data\\1-1-1.jpg'\n",
    "trs = tr.Compose([\n",
    "    tr.ToTensor(),\n",
    "    # tr.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "input = trs(Image.open(path).convert('RGB').resize((224,224)))\n",
    "input_two = trs(Image.open(path_).convert('RGB').resize((224,224)))\n",
    "# model(input.unsqueeze_)\n",
    "input_ = torch.unsqueeze(input,0)\n",
    "input_two_ = torch.unsqueeze(input_two,0)\n",
    "# output= model(input_)\n",
    "# accuracy()\n",
    "# input_.shape\n",
    "# _, pred = output.topk(1, 1, True, True)\n",
    "# [k for k, v in lable.items() if v == pred][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 224, 224])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from timm.models.vision_transformer import PatchEmbed, Block\n",
    "patch_embed = PatchEmbed()\n",
    "a = patch_embed(input_)\n",
    "b = patch_embed(input_two_)  ### 中间这个表示每一块的 16* 16\n",
    "# c = a==b \n",
    "input_two.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "proj = nn.Conv2d(3, 768, kernel_size=16, stride=16, bias=False) ### 1,3 ,224 ,224 => 1,768,14,14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[768.0000, 768.0000, 756.5648,  ..., 768.0000, 768.0000, 768.0000],\n",
       "          [768.0000, 768.0000,   0.0000,  ...,   0.0000,   0.0000, 768.0000],\n",
       "          [768.0000, 768.0000,   0.0000,  ...,   0.0000,   0.0000, 768.0000],\n",
       "          ...,\n",
       "          [768.0000, 768.0000,   0.0000,  ...,   0.0000,   0.0000, 768.0000],\n",
       "          [768.0000, 768.0000, 768.0000,  ..., 768.0000, 768.0000, 768.0000],\n",
       "          [768.0000, 768.0000, 768.0000,  ..., 768.0000, 768.0000, 768.0000]],\n",
       "\n",
       "         [[768.0000, 768.0000, 756.5648,  ..., 768.0000, 768.0000, 768.0000],\n",
       "          [768.0000, 768.0000,   0.0000,  ...,   0.0000,   0.0000, 768.0000],\n",
       "          [768.0000, 768.0000,   0.0000,  ...,   0.0000,   0.0000, 768.0000],\n",
       "          ...,\n",
       "          [768.0000, 768.0000,   0.0000,  ...,   0.0000,   0.0000, 768.0000],\n",
       "          [768.0000, 768.0000, 768.0000,  ..., 768.0000, 768.0000, 768.0000],\n",
       "          [768.0000, 768.0000, 768.0000,  ..., 768.0000, 768.0000, 768.0000]],\n",
       "\n",
       "         [[768.0000, 768.0000, 756.5648,  ..., 768.0000, 768.0000, 768.0000],\n",
       "          [768.0000, 768.0000,   0.0000,  ...,   0.0000,   0.0000, 768.0000],\n",
       "          [768.0000, 768.0000,   0.0000,  ...,   0.0000,   0.0000, 768.0000],\n",
       "          ...,\n",
       "          [768.0000, 768.0000,   0.0000,  ...,   0.0000,   0.0000, 768.0000],\n",
       "          [768.0000, 768.0000, 768.0000,  ..., 768.0000, 768.0000, 768.0000],\n",
       "          [768.0000, 768.0000, 768.0000,  ..., 768.0000, 768.0000, 768.0000]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[768.0000, 768.0000, 756.5648,  ..., 768.0000, 768.0000, 768.0000],\n",
       "          [768.0000, 768.0000,   0.0000,  ...,   0.0000,   0.0000, 768.0000],\n",
       "          [768.0000, 768.0000,   0.0000,  ...,   0.0000,   0.0000, 768.0000],\n",
       "          ...,\n",
       "          [768.0000, 768.0000,   0.0000,  ...,   0.0000,   0.0000, 768.0000],\n",
       "          [768.0000, 768.0000, 768.0000,  ..., 768.0000, 768.0000, 768.0000],\n",
       "          [768.0000, 768.0000, 768.0000,  ..., 768.0000, 768.0000, 768.0000]],\n",
       "\n",
       "         [[768.0000, 768.0000, 756.5648,  ..., 768.0000, 768.0000, 768.0000],\n",
       "          [768.0000, 768.0000,   0.0000,  ...,   0.0000,   0.0000, 768.0000],\n",
       "          [768.0000, 768.0000,   0.0000,  ...,   0.0000,   0.0000, 768.0000],\n",
       "          ...,\n",
       "          [768.0000, 768.0000,   0.0000,  ...,   0.0000,   0.0000, 768.0000],\n",
       "          [768.0000, 768.0000, 768.0000,  ..., 768.0000, 768.0000, 768.0000],\n",
       "          [768.0000, 768.0000, 768.0000,  ..., 768.0000, 768.0000, 768.0000]],\n",
       "\n",
       "         [[768.0000, 768.0000, 756.5648,  ..., 768.0000, 768.0000, 768.0000],\n",
       "          [768.0000, 768.0000,   0.0000,  ...,   0.0000,   0.0000, 768.0000],\n",
       "          [768.0000, 768.0000,   0.0000,  ...,   0.0000,   0.0000, 768.0000],\n",
       "          ...,\n",
       "          [768.0000, 768.0000,   0.0000,  ...,   0.0000,   0.0000, 768.0000],\n",
       "          [768.0000, 768.0000, 768.0000,  ..., 768.0000, 768.0000, 768.0000],\n",
       "          [768.0000, 768.0000, 768.0000,  ..., 768.0000, 768.0000, 768.0000]]]],\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_ = torch.ones(768,3,16,16)\n",
    "a_ = torch.nn.Parameter(a_)\n",
    "a_ = a_.to(dtype=torch.float32)\n",
    "proj.weight = a_\n",
    "y = proj(input_)\n",
    "torch.mul(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 768, 14, 14])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_ = torch.ones(768,3,16,16)\n",
    "a_ = torch.nn.Parameter(a_)\n",
    "a_ = a_.to(dtype=torch.float32)\n",
    "proj.weight = a_\n",
    "x = proj(input_two_)\n",
    "# F.conv2d(input=input_two,weight=weight,stride=2,padding='valid')\n",
    "# weight\n",
    "# a_\n",
    "# x= x.to(dtype=torch.int)\n",
    "x = x > 0\n",
    "x = x.to(dtype=torch.float)\n",
    "# x = torch.unsqueeze(x,0)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14, 14)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import collections\n",
    "from itertools import repeat\n",
    "def _ntuple(n):\n",
    "    def parse(x):\n",
    "        if isinstance(x, collections.abc.Iterable) and not isinstance(x, str):\n",
    "            return tuple(x)\n",
    "        return tuple(repeat(x, n))\n",
    "    return parse\n",
    "to_2tuple = _ntuple(2)\n",
    "to_2tuple(21)\n",
    "to_2tuple(224)\n",
    "grid_size = tuple([s // p for s, p in zip(to_2tuple(224), to_2tuple(16))])\n",
    "grid_size### 每个窗格大小是14 * 14 步长是16  卷积核是16 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
