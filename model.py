from models import *
from eval_combined import main
def tt():
    import timm
    mymodel = build_model_v1(11,num_class=20)
    pretrain_weight = timm.create_model('vit_small_patch16_224', num_classes=20,pretrained=True).state_dict()
    mymodel.load_state_dict(pretrain_weight, strict=True)
    # print(pretrain_weight)
    import torch
    print(torch.__version__)
    print(torch.cuda.is_available())
    print('版本',torch.backends.cudnn.version())
    torch.cuda.device_count()
    
    print(pretrain_weight)

    import torch
    print(torch.cuda.is_available())
    
    num_gpu= 1
    # Decide which device we want to run on
    device = torch.device("cuda:0" if (torch.cuda.is_available() and num_gpu > 0) else "cpu")
    print(device)
    print(torch.cuda.get_device_name(0))

    print('-'*20)
    import torch
    print(torch.cuda.is_available())
    
    num_gpu= 1
    # Decide which device we want to run on
    device = torch.device("cuda:0" if (torch.cuda.is_available() and num_gpu > 0) else "cpu")
    print(device)
    print(torch.cuda.get_device_name(0))
    print(torch.rand(3,3).cuda())



print('-'*30)
import torch.nn as nn
from sklearn.metrics import confusion_matrix, roc_auc_score, f1_score

def main1():
    output_list = []
    confusion_label = []
    confusion_pred = []
    softmax = nn.Softmax()
    a = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19]
    label = torch.tensor([ 1, 10, 13,  8, 19, 15,  6,  4,  8,  9,  0, 18,  4, 13,  7,  6],       device='cuda:0')
    output = torch.tensor([[-4.8672e-01, -7.3882e-02, -1.1710e-01,  4.5768e-01, -1.9477e-01,         -2.9468e-01,  6.1081e-01,  2.9094e-01,  4.5018e-01, -1.3252e-01,          8.2160e-01,  1.4636e-01, -9.1479e-02,  1.4585e-01, -3.4739e-01,          3.2302e-01,  1.4891e-01,  2.3332e-01,  6.0692e-01, -2.6499e-02],        [ 7.1814e-02, -2.6202e-01,  1.0117e-01,  8.9492e-01, -4.5599e-02,          4.9152e-01,  4.3789e-01, -7.5101e-02,  3.8974e-01,  6.0738e-01,          4.0519e-02,  5.1836e-01,  6.0558e-01,  1.2006e-02, -4.5464e-02,          6.3881e-01, -2.8227e-01,  8.2316e-02, -6.4231e-01,  3.9347e-02],        [ 2.4028e-03, -2.0022e-01, -1.4920e-01,  8.6359e-01, -1.4063e-01,          4.6102e-01,  6.3071e-01,  9.2361e-02,  2.9330e-01,  2.4399e-01,          5.0827e-01,  1.2024e-01,  3.6211e-02,  3.3545e-01, -3.1177e-01,          7.4902e-01, -2.0422e-01,  2.1897e-01, -3.6609e-01,  1.1351e-01],        [-3.4312e-01, -6.3081e-01, -1.3361e-01,  9.4144e-01, -5.1453e-01,          5.4202e-01,  4.8722e-01,  6.4310e-02, -1.3946e-01,  1.9114e-01,          7.4520e-02, -1.6268e-01,  1.7475e-01,  6.0045e-01, -5.1414e-01,          7.0034e-01, -4.5700e-01, -5.3347e-02, -6.8572e-01,  1.8951e-02],        [ 1.6183e-01,  3.5340e-02,  1.7061e-01,  8.7675e-01,  4.4841e-03,         -3.7402e-02,  5.9444e-01,  5.7997e-02,  5.2176e-01,  4.7726e-01,          7.5555e-01,  3.4907e-01,  6.0963e-02,  2.2292e-01, -3.7617e-01,          8.2447e-01,  6.0641e-02,  1.0309e-01, -1.3964e-01,  3.2078e-02],        [-4.3663e-01, -2.6258e-01, -1.2802e-01,  5.8390e-01, -3.5325e-01,          3.2085e-02,  5.4597e-01,  2.7649e-01,  3.8422e-01, -1.5773e-02,          8.1434e-01, -4.8882e-02, -1.2283e-01,  3.1648e-01, -4.0464e-01,          4.5178e-01, -4.6626e-03,  2.6326e-01,  2.6150e-01,  5.3205e-02],        [ 5.9937e-01, -1.8425e-01,  2.9361e-01,  2.0710e-01,  5.3598e-01,          7.6340e-02,  1.7586e-01,  7.5766e-02,  5.3098e-01,  5.3245e-01,         -5.1468e-01,  6.1445e-01, -3.9041e-02, -4.1917e-01,  2.5510e-01,          3.0453e-01, -1.9052e-01,  2.0521e-01, -3.1952e-01, -5.8373e-02],        [-4.1600e-01,  4.0207e-02, -1.5334e-01,  3.8975e-01, -8.9635e-02,         -2.6761e-01,  5.2572e-01,  2.9745e-01,  5.0394e-01, -2.2369e-01,          7.6490e-01,  1.9958e-01, -8.8550e-02,  1.2479e-01, -2.1357e-01,          3.7248e-01,  1.6478e-01,  1.9684e-01,  5.8426e-01,  3.5918e-02],        [-6.9584e-02, -2.1618e-01, -1.6636e-01,  4.8467e-01, -2.9530e-02,          1.2837e-01,  4.6839e-01,  1.7947e-01,  3.7900e-01, -5.3356e-02,          5.1725e-01,  2.0935e-01, -9.8348e-02,  1.0734e-01, -2.0480e-01,          5.5266e-01, -5.3965e-02,  3.6981e-01,  4.7810e-02,  1.5431e-01],        [ 3.7767e-01,  2.7422e-02,  2.2167e-01, -6.3122e-02,  7.1665e-03,          4.4875e-02,  3.8104e-01, -2.9434e-01, -2.8577e-01,  1.9617e-01,         -5.8302e-01, -3.2378e-01,  4.6601e-02, -6.6471e-01,  2.7083e-01,          3.9895e-01,  1.9620e-02, -1.9029e-01, -6.3514e-01,  9.4444e-02],        [ 3.4751e-01,  1.0923e-01,  1.3694e-01,  3.2501e-01,  1.1076e-01,          1.1047e-01,  3.6588e-01, -1.1686e-02,  5.1982e-01,  5.8833e-02,          1.4618e-01,  5.4680e-01, -1.7314e-01, -5.7748e-01,  1.5071e-01,          5.2492e-01,  1.2285e-01,  1.5152e-01,  2.2596e-01, -1.7598e-01],        [ 5.3010e-01,  1.1419e-01,  4.0035e-01,  1.0681e-01,  1.5395e-02,         -1.6052e-02,  5.6414e-01, -1.4064e-01,  7.0575e-02, -8.5265e-03,         -6.0425e-01, -3.5351e-02,  2.2988e-01, -4.4555e-01,  3.1763e-01,          4.1782e-01, -4.3732e-02, -8.6097e-02, -7.4332e-01, -4.1917e-02],        [ 6.2261e-01,  8.0996e-02,  2.2323e-01, -1.0748e-01,  3.3795e-01,          5.7854e-02,  5.2897e-05, -4.0111e-02,  1.7570e-01, -2.1774e-01,         -6.5970e-01,  7.0338e-01, -1.8456e-01, -6.1844e-01,  2.9787e-01,          2.9691e-01, -1.3031e-01,  1.3515e-01, -3.1421e-01, -1.3746e-01],        [-6.3550e-01, -1.2021e-02, -1.0205e-01,  3.9602e-01, -1.6642e-01,         -3.2515e-01,  5.0609e-01,  3.0758e-01,  4.2287e-01, -1.2716e-01,          8.2638e-01,  1.4627e-01, -5.8853e-02,  2.2731e-01, -3.7835e-01,          2.5256e-01,  8.8868e-02,  2.0248e-01,  6.4972e-01, -3.9235e-02],        [-9.1474e-02,  8.2737e-02, -8.7550e-02,  8.9067e-01, -3.9625e-01,          1.7596e-01,  7.9852e-01,  2.4333e-01,  4.1358e-01, -8.8005e-03,          8.9842e-01,  1.1401e-01, -1.7924e-01,  2.5210e-01, -4.4488e-01,          7.0136e-01, -2.9427e-02,  1.3666e-01,  2.1006e-01,  3.0632e-02],        [-5.0401e-01, -1.4001e-01, -8.2674e-03,  1.0380e+00, -6.8269e-01,          4.6112e-02,  6.4798e-01,  1.5819e-01,  2.3788e-01,  6.0057e-01,          8.8807e-01, -1.3133e-01,  3.7126e-01,  5.5600e-01, -3.2121e-01,          6.8420e-01, -4.4582e-01, -7.1394e-02, -4.5122e-01, -3.7594e-01]],       device='cuda:0')
    # print((output.argmax(dim=1) == label).float().sum().item())
    output_list.append(output)
    output_list.append(output)

    confusion_label += list(label.cpu().numpy())
    confusion_label += list(label.cpu().numpy())

    confusion_pred += list(output.argmax(dim=1).squeeze().cpu().numpy())
    confusion_pred += list(output.argmax(dim=1).squeeze().cpu().numpy())


    out_cat = softmax(torch.cat(output_list, dim=0)).cpu().numpy()# shape 400 20
    out_cat_max = out_cat.max(axis=1)
    print(out_cat_max,out_cat_max.shape,out_cat.shape)
    print(confusion_label)
    print(len(out_cat_max),len(confusion_label))
    #auc = roc_auc_score(confusion_label, out_cat_max)
    f1 = f1_score(confusion_label, confusion_pred, average='weighted')
    print(f1)    

# tt()
def bbb():
    a = torch.tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1881, 0.1835, 0.1239,
        0.2339, 0.2936, 0.1239, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0596, 0.4266, 0.6651, 0.9633, 0.7798, 1.0000, 0.9037, 0.7431, 0.6835,
        0.3119, 0.2248, 0.1330, 0.0000, 0.0000, 0.0000, 0.1514, 0.2523, 0.5229,
        0.4541, 0.6284, 0.5596, 0.4725, 0.4908, 0.2431, 0.1376, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.1239, 0.1330, 0.3073, 0.3532, 0.3394,
        0.2844, 0.1697, 0.1239, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.1376, 0.2339, 0.2064, 0.1193, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000])
    import matplotlib.pyplot as plt
    mask_indexes = torch.argsort(a, descending=True)[:64]

    new_zeros = torch.zeros((16*16), dtype=torch.uint8)
    new_gaze_mask = new_zeros == 1
    # plt.imshow(new_gaze_mask)
    new_gaze_mask[mask_indexes] = True
    # plt.show()
    print(new_gaze_mask)
import pathlib as pl
def write_smap_to():
    lines = open('data/test.csv').readlines()
    for i in lines:
        print(i)
        img_path  = i.splitlines()[0]
        main(img_path=pl.Path(img_path))

write_smap_to()